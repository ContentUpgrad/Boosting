{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing the libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import plotly.offline as py\n",
    "import plotly.graph_objs as go\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import (accuracy_score, log_loss, confusion_matrix)\n",
    "#Suppressing warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1 - Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Importing  the Dataset\n",
    "df = pd.read_csv('WA_Fn-UseC_-HR-Employee-Attrition.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(3)\n",
    "\n",
    "# Dep Var - Attrition ( Yes/No) - Binary Classification Problem \n",
    "\n",
    "# 34 - indepedent variable "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking the number of 'Yes' and 'No' in 'Attrition'\n",
    "ax = sns.catplot(x=\"Attrition\", kind=\"count\", palette=\"ch:.25\", data=df);\n",
    "ax.set(xlabel = 'Attrition', ylabel = 'Number of Employees')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "checking if any missing values in the dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Identifying columns with missing information\n",
    "missing_col = df.columns[df.isnull().any()].values\n",
    "print('The missing columns in the dataset are: ',missing_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2 - Feature Engineering\n",
    "\n",
    "The numeric and categorical fields need to be treated separately.The following few steps separate the numeric and categorical fields and drops the target field 'Attrition' from the feature set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['JobRole'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting the Numeric and Categorical features\n",
    "df_num = pd.DataFrame(data = df.select_dtypes(include = ['int64']))\n",
    "df_cat = pd.DataFrame(data = df.select_dtypes(include = ['object']))\n",
    "print(\"Shape of Numeric: \",df_num.shape)\n",
    "print(\"Shape of Categorical: \",df_cat.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Encoding Categorical Fields\n",
    "\n",
    "The categorical fields have been encoded using the get_dummies() function of Pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropping 'Attrition' from df_cat before encoding\n",
    "df_cat = df_cat.drop(['Attrition'], axis=1) \n",
    "\n",
    "#Encoding using Pandas' get_dummies\n",
    "df_cat_encoded = pd.get_dummies(df_cat)\n",
    "df_cat_encoded.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Scaling Numeric Fields\n",
    "\n",
    "The numeric fields have been scaled next for best results. `StandardScaler()` has been used for the same. After scaling the numeric features, they will be merged with the categorical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combining the Categorical and Numeric features\n",
    "df_transformed_final = pd.concat([df_num_scaled,df_cat_encoded], axis = 1)\n",
    "print(\"Shape of final dataframe: \",df_transformed_final.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combining the Categorical and Numeric features\n",
    "df_transformed_final = pd.concat([df_num,df_cat_encoded], axis = 1)\n",
    "print(\"Shape of final dataframe: \",df_transformed_final.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting the target variable - 'Attrition'\n",
    "target = df['Attrition']\n",
    "\n",
    "#Mapping 'Yes' to 1 and 'No' to 0\n",
    "map = {'Yes':1, 'No':0}\n",
    "target = target.apply(lambda x: map[x])\n",
    "\n",
    "print(\"Shape of target: \",target.shape)\n",
    "\n",
    "X = df_transformed_final #Features\n",
    "y = target #Target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Train and Test Split\n",
    "\n",
    "The data is next split into training and test dataset using the train_test_split functionality of sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting into Train and Test dataset in 80-20 ratio\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,train_size = 0.8, random_state = 0, stratify = y)\n",
    "print(\"Shape of X Train: \",X_train.shape)\n",
    "print(\"Shape of X Test: \",X_test.shape)\n",
    "print(\"Shape of y Train: \",y_train.shape)\n",
    "print(\"Shape of y Test: \",y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3 - Model Fitting\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adaboost Classifier\n",
    "##### The most important parameters are base_estimator, n_estimators and learning_rate.\n",
    "\n",
    "##### 1. base_estimator  - It is the learning algorithm to use to train the weak models. The default Learning Algorithm is DecisionTreeClassifier with Max Depth of 1\n",
    "\n",
    "#####  2. n_estimators - It is the number of models to iteratively train.\n",
    "\n",
    "#####  3.learning_rate - It is the contribution of each model to the weights and default value for it is 1. There is a trade-off between learning_rate and n_estimators. Reducing the learning rate will forcing the model train slower (but sometimes resulting in better performance scores). Decreasing the learning rate L makes the coefficients Î±_m smaller, which reduces the amplitude of the sample_weights at each step (As per weight formula we use at each step for updating weights). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using adaBoosting to predict 'Attrition' \n",
    "adaboost =  AdaBoostClassifier(n_estimators=200, random_state=1)\n",
    "\n",
    "\n",
    "# No of Models \n",
    "\n",
    "# from sklearn.ensemble.AdaBoost\n",
    "# Accuracy or AUC is chagin with no of Model ( Weak Models )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fitting Model\n",
    "adaboost.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pred\n",
    "y_pred = adaboost.predict(X_test)\n",
    "\n",
    "\n",
    "# from sklearn.metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy of the model is:  ',accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print('The confusion Matrix : \\n',cm)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
